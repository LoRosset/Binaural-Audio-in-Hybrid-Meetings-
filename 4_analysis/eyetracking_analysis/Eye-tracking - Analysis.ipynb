{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye-tracking : analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#numpy and panda for data structure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "from tslearn.metrics import dtw_path_from_metric\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from matplotlib._png import read_png\n",
    "from matplotlib.cbook import get_sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to \"Eye-tracking analysis - Extract fixations.ipynb\" on how the files in folder \"/fixations\" should be generated from the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacking fixation data\n",
    "fix_original_all_d1, fix_original_all_d2, fix_original_all_d3, fix_original_all_d4, fix_original_all_d5, fix_original_all_d6 = [\n",
    "    pd.read_csv(\"./fixations/dialog\"+str(i)+\"_fixations_42_original.csv\", index_col=0) for i in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all = pd.concat([fix_original_all_d1, fix_original_all_d2, fix_original_all_d3, fix_original_all_d4, fix_original_all_d5, fix_original_all_d6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixations_original_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the same id in each condition for the same participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ids of participants\n",
    "path_original_all = \"./participants/42_original.csv\"\n",
    "original_all = pd.read_csv(path_original_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_original_all = original_all[['dialog1','dialog2','dialog3','dialog4','dialog5','dialog6']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_original_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ids_original_all)):    \n",
    "    for index in ids_original_all[i]:\n",
    "#         fixations_original_all.loc[(fixations_original_all.tester_id == index), 'tester_id'] = i\n",
    "        print(index)\n",
    "        print(i)\n",
    "#         print(fixations_original_all.tester_id)\n",
    "        print(\"---------\")\n",
    "#         fixations_original_all.loc[(fixations_original_all.tester_id == index), 'tester_id_new'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids_original_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all.tester_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tester_id is equal to PID in the surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixations_original_all.loc[fixations_original_all.tester_id == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixations_original_all.to_csv('fixations_original_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixation duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a recall, the fixations were identified with a gaze velocity threshold of 21px/s, and a minimum fixation duration of 100ms on denoised data (interpolation for 60Hz and noise reduction level using median of 21 consecutives points).\n",
    "\n",
    "see: https://support.realeye.io/fixation-filter/#:~:text=Fixation%20is%20a%20series%20of,terms%20of%20time%20and%20space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, I compute the mean fixation duration (of the fixation points) for each participant in each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_mean_fix_duration_original_all = []\n",
    "for part_id in range(len(fixations_original_all.tester_id.unique())):\n",
    "    participant_values = []\n",
    "    for item_name in fixations_original_all.index.unique():\n",
    "        nb_fixation = fixations_original_all.loc[\n",
    "            (fixations_original_all.index ==item_name) \n",
    "            & (fixations_original_all.tester_id == part_id)].shape[0]\n",
    "        total_duration = np.sum(\n",
    "            fixations_original_all.loc[\n",
    "                (fixations_original_all.index ==item_name) \n",
    "                & (fixations_original_all.tester_id == part_id), 'fixation_duration_ms'].tolist())\n",
    "        mean_dur = total_duration/nb_fixation\n",
    "        participant_values.append(mean_dur)\n",
    "    participant_mean_fix_duration_original_all.append(participant_values)\n",
    "participant_mean_fix_duration_original_all = pd.DataFrame(participant_mean_fix_duration_original_all, columns=fixations_original_all.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_mean_fix_duration_original_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_mean_fix_duration_original_all.to_csv('participant_mean_fix_duration_original_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then I compute the mean fixation duration per video (real analysis on SPSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fix_duration_original_all = {}\n",
    "for dialog in participant_mean_fix_duration_original_all.keys():\n",
    "    mean_fix_duration_original_all[dialog]=np.mean(participant_mean_fix_duration_original_all[dialog].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fix_duration_original_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** SPSS reference: https://www.statisticssolutions.com/the-wilcoxon-sign-test-in-spss/#:~:text=The%20Wilcoxon%20sign%20test%20is,or%20with%20ranked%2Fordinal%20data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total fixation duration (ratio with duration of each video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, I compute the total fixation duration for each participant in each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_durations = []\n",
    "# dialog_durations.append(fixations_original_all.index.unique().tolist())\n",
    "dialog_name = ['dialog1_normal_mask','dialog2_head_mask','dialog3_spatial','dialog4_head','dialog5_spatial_mask','dialog6_normal']\n",
    "dialog_durations.append(dialog_name)\n",
    "dialog_durations.append([143800,116400,130240,104200,124160,135200])\n",
    "dialog_durations = pd.DataFrame(dialog_durations, columns=dialog_durations.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_total_fix_duration_original_all = []\n",
    "for part_id in range(len(fixations_original_all.tester_id.unique())):\n",
    "    participant_values = []\n",
    "    for item_name in fixations_original_all.index.unique():\n",
    "        total_duration = np.sum(\n",
    "            fixations_original_all.loc[\n",
    "                (fixations_original_all.index ==item_name) \n",
    "                & (fixations_original_all.tester_id == part_id), 'fixation_duration_ms'].tolist())\n",
    "        ratio = total_duration / dialog_durations[item_name].values.item()\n",
    "        participant_values.append(ratio)\n",
    "    participant_total_fix_duration_original_all.append(participant_values)\n",
    "participant_total_fix_duration_original_all = pd.DataFrame(participant_total_fix_duration_original_all, columns=fixations_original_all.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all.tester_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_total_fix_duration_original_all.to_csv('participant_total_fix_duration_original_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then I compute the mean total fixation duration based on these values (real analysis on SPSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_total_fix_duration_original_all = {}\n",
    "for dialog in participant_total_fix_duration_original_all.keys():\n",
    "    mean_total_fix_duration_original_all[dialog]=np.mean(participant_total_fix_duration_original_all[dialog].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_total_fix_duration_original_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixation number ratio with duration of the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_nb_fixation = []\n",
    "for part_id in range(len(fixations_original_all.tester_id.unique())):\n",
    "    participant_values = []\n",
    "    for item_name in fixations_original_all.index.unique():\n",
    "        nb_fixation = fixations_original_all.loc[\n",
    "                (fixations_original_all.index ==item_name) \n",
    "                & (fixations_original_all.tester_id == part_id)].shape[0]\n",
    "        ratio = nb_fixation / dialog_durations[item_name].values.item()\n",
    "        participant_values.append(ratio)\n",
    "    participant_nb_fixation.append(participant_values)\n",
    "participant_nb_fixation = pd.DataFrame(participant_nb_fixation, columns=fixations_original_all.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_nb_fixation.to_csv('nb_fixation.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nb_fix = {}\n",
    "for dialog in participant_nb_fixation.keys():\n",
    "    mean_nb_fix[dialog]=np.mean(participant_nb_fixation[dialog].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nb_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean saccades amplitude per participant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saccade amplitude is the distance between two successive fixation points produced by one participant.\n",
    "Thus, to compute the saccade amplitudes I calculate the euclidean distance between all successive fixation points. The euclidean distance is also the L2 distance, thus I use the numpy.linalg.norm function to calculate the euclidean distance for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixations_original_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_points = fixations_original_all.loc[(fixations_original_all.tester_id==0) & (fixations_original_all.index == 'dialog1_normal_mask'),\"fixation_point_x\":\"fixation_point_y\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dist = []\n",
    "for index, elem in enumerate(list_points):\n",
    "    if (index+1 < len(list_points)):\n",
    "        point_start = np.array(elem)\n",
    "        point_end = np.array(list_points[index+1])\n",
    "        dist = np.linalg.norm(point_end-point_start)\n",
    "    list_dist.append(dist)\n",
    "mean_saccade_amplitude = np.mean(list_dist)\n",
    "print(mean_saccade_amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_saccade_amplitude_original_all = []\n",
    "for part_id in range(len(fixations_original_all.tester_id.unique())):\n",
    "    participant_values = []\n",
    "    for item_name in fixations_original_all.index.unique():\n",
    "        list_points = fixations_original_all.loc[\n",
    "            (fixations_original_all.tester_id==part_id) & (fixations_original_all.index == item_name),\n",
    "            \"fixation_point_x\":\"fixation_point_y\"].values.tolist()\n",
    "        list_dist = []\n",
    "        for index, elem in enumerate(list_points):\n",
    "            if (index+1 < len(list_points)):\n",
    "                point_start = np.array(elem)\n",
    "                point_end = np.array(list_points[index+1])\n",
    "                dist = np.linalg.norm(point_end-point_start)\n",
    "            list_dist.append(dist)\n",
    "        mean_saccade_amplitude = np.mean(list_dist)\n",
    "        participant_values.append(mean_saccade_amplitude)\n",
    "    participant_saccade_amplitude_original_all.append(participant_values)\n",
    "participant_saccade_amplitude_original_all = pd.DataFrame(participant_saccade_amplitude_original_all, columns=fixations_original_all.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_saccade_amplitude_original_all.to_csv('participant_mean_saccade_amplitude_original_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then I compute the mean saccade amplitude for each condition with the above values (real analysis on SPSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_saccade_amplitude_original_all = {}\n",
    "for dialog in participant_saccade_amplitude_original_all.keys():\n",
    "    mean_saccade_amplitude_original_all[dialog]=np.mean(participant_saccade_amplitude_original_all[dialog].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_saccade_amplitude_original_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal analysis (frame by frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion (Fixations points variability per frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dispersion is the mean of the Euclidian distances between multiple observers points. In the following, the focus is put on the dispersion of fixation points for each frame of each condition.\n",
    "\n",
    "All the videos have a frame rate of 25 frame/s. Thus, for each frame, we calculate the mean of the euclidean distances over all the fixation points on the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First I need to regroup all the fixation points per frame for each dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame correspond to a duration of 40 ms. Thus, to have the fixation points for each frame, I regroup all the fixation points that appear on it in the interval of time of the frame (0-40, 41-80, 81-120, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixations_original_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialog_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment the next line to execute this cell\n",
    "# %%script false --no-raise-error\n",
    "# structure : \n",
    "# first level = dialog1, dialog2, ...\n",
    "# second level = frame 1, frame 2, ... \n",
    "# third level = fixation point 1, fixation point 2, ..\n",
    "frame_time = round(1000 / 25)\n",
    "fixation_points_per_frame = []\n",
    "for item_name in fixations_original_all.index.unique(): # 6 dialogs\n",
    "    list_points_dialog = []\n",
    "    for frame_nb in range(0, round(dialog_durations[[item_name]].values.item() / frame_time)): # each frame\n",
    "        frame_begin = frame_nb * frame_time\n",
    "        frame_end = (frame_nb+1) * frame_time\n",
    "        list_points_frame = fixations_original_all.loc[\n",
    "                (fixations_original_all.index == item_name)\n",
    "                & (\n",
    "                    (\n",
    "                        (fixations_original_all.fixation_starts_at_ms >= frame_begin) \n",
    "                        & (fixations_original_all.fixation_starts_at_ms < frame_end)\n",
    "                        & (fixations_original_all.fixation_ends_at_ms > frame_end)\n",
    "                    ) |\n",
    "                    (\n",
    "                        (fixations_original_all.fixation_starts_at_ms <= frame_begin)\n",
    "                        & (fixations_original_all.fixation_ends_at_ms > frame_begin )\n",
    "                        & (fixations_original_all.fixation_ends_at_ms < frame_end )\n",
    "                    ) |\n",
    "                    (\n",
    "                        (fixations_original_all.fixation_starts_at_ms >= frame_begin)\n",
    "                        & (fixations_original_all.fixation_starts_at_ms < frame_end)\n",
    "                        & (fixations_original_all.fixation_ends_at_ms > frame_begin)\n",
    "                        & (fixations_original_all.fixation_ends_at_ms < frame_end)\n",
    "                    ) |\n",
    "                        (\n",
    "                            (fixations_original_all.fixation_starts_at_ms <= frame_begin)\n",
    "                            & (fixations_original_all.fixation_ends_at_ms >= frame_end)\n",
    "                        )\n",
    "                  ),\n",
    "                \"fixation_point_x\":\"fixation_point_y\"].values.tolist() # set of points\n",
    "        list_points_dialog.append(list_points_frame)\n",
    "    fixation_points_per_frame.append(list_points_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store fixation_points_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r fixation_points_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_points_per_frame = []\n",
    "fixation_dialog = []\n",
    "fixation_frame = []\n",
    "count_dialog = 1\n",
    "\n",
    "with open('./stored_variables/fixations_points_per_frame.txt') as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        count_br = line.count(\"[\")\n",
    "        line = line.replace(\"[\", \"\")\n",
    "        line = line.replace(\"]\", \"\")\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        line = line.replace(\" \", \"\")\n",
    "        \n",
    "        fixation_value = []\n",
    "        for i in line.split(','):\n",
    "            if i != '':\n",
    "                fixation_value.append(int(i))\n",
    "        if (count_br > 3) or (count_br == 1):\n",
    "            if (count_br > 3):\n",
    "                print(line)\n",
    "            fixation_frame.append(fixation_value)\n",
    "        elif count_br == 2:\n",
    "            fixation_dialog.append(fixation_frame)\n",
    "            fixation_frame = []\n",
    "            fixation_frame.append(fixation_value)\n",
    "        else: #count_br == 3\n",
    "            fixation_points_per_frame.append(fixation_dialog)\n",
    "            fixation_dialog = []\n",
    "            count_dialog = count_dialog + 1\n",
    "            fixation_frame = []\n",
    "            fixation_frame.append(fixation_value)\n",
    "    fixation_points_per_frame.append(fixation_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation points per participant per frame (used later for scanpath vizualisation in 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all.tester_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment the next line to execute this cell\n",
    "# %%script false --no-raise-error\n",
    "# structure : \n",
    "# first level = dialog1, dialog2, ...\n",
    "# second level = participant1, participant2, ...\n",
    "# third level = frame 1, frame 2, ... \n",
    "# fourth level = fixation point 1, fixation point 2, ..\n",
    "frame_time = round(1000 / 25)\n",
    "fixation_points_per_participant_per_frame = []\n",
    "for item_name in fixations_original_all.index.unique(): # 6 dialogs\n",
    "    list_points_dialog = []\n",
    "    for tester_id in fixations_original_all.tester_id.unique(): # each pariticpant\n",
    "        list_points_participant = []\n",
    "        for frame_nb in range(0, round(dialog_durations[[item_name]].values.item() / frame_time)): # each frame\n",
    "            frame_begin = frame_nb * frame_time\n",
    "            frame_end = (frame_nb+1) * frame_time\n",
    "            list_points_frame = fixations_original_all.loc[\n",
    "                    (fixations_original_all.index == item_name)\n",
    "                    & (fixations_original_all.tester_id == tester_id)\n",
    "                    & (\n",
    "                        (\n",
    "                            (fixations_original_all.fixation_starts_at_ms >= frame_begin) \n",
    "                            & (fixations_original_all.fixation_starts_at_ms < frame_end)\n",
    "                            & (fixations_original_all.fixation_ends_at_ms > frame_end)\n",
    "                        ) |\n",
    "                        (\n",
    "                            (fixations_original_all.fixation_starts_at_ms <= frame_begin)\n",
    "                            & (fixations_original_all.fixation_ends_at_ms > frame_begin )\n",
    "                            & (fixations_original_all.fixation_ends_at_ms < frame_end )\n",
    "                        ) |\n",
    "                        (\n",
    "                            (fixations_original_all.fixation_starts_at_ms >= frame_begin)\n",
    "                            & (fixations_original_all.fixation_starts_at_ms < frame_end)\n",
    "                            & (fixations_original_all.fixation_ends_at_ms > frame_begin)\n",
    "                            & (fixations_original_all.fixation_ends_at_ms < frame_end)\n",
    "                        ) |\n",
    "                        (\n",
    "                            (fixations_original_all.fixation_starts_at_ms <= frame_begin)\n",
    "                            & (fixations_original_all.fixation_ends_at_ms >= frame_end)\n",
    "                        )\n",
    "                      ),\n",
    "                    \"fixation_point_x\":\"fixation_point_y\"].values.tolist()\n",
    "            list_points_participant.append(list_points_frame)\n",
    "        list_points_dialog.append(list_points_participant)\n",
    "    fixation_points_per_participant_per_frame.append(list_points_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all.tester_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store fixation_points_per_participant_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r fixation_points_per_participant_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_points_per_participant_per_frame = pd.read_pickle(r'fixation_points_per_participant_per_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixation_points_per_participant_per_frame = []\n",
    "# fixation_dialog = []\n",
    "# fixation_participant = []\n",
    "# fixation_frame = []\n",
    "# count_dialog = 1\n",
    "\n",
    "# with open('./stored_variables/fixation_points_per_participant_per_frame.txt') as f:\n",
    "    \n",
    "#     for line in f.readlines():\n",
    "#         count_br = line.count(\"[\")\n",
    "#         line = line.replace(\"[\", \"\")\n",
    "#         line = line.replace(\"]\", \"\")\n",
    "#         line = line.replace(\"\\n\", \"\")\n",
    "#         line = line.replace(\" \", \"\")\n",
    "        \n",
    "#         fixation_value = []\n",
    "#         for i in line.split(','):\n",
    "#             if i != '':\n",
    "#                 fixation_value.append(int(i))\n",
    "#         if (count_br > 4) or (count_br == 1):\n",
    "#             if (count_br > 4):\n",
    "#                 print(line)\n",
    "#             fixation_frame.append(fixation_value)\n",
    "#         elif count_br >= 1:\n",
    "#             fixation_dialog.append(fixation_frame)\n",
    "#             fixation_frame = []\n",
    "#             fixation_frame.append(fixation_value)\n",
    "#         elif count_br == 3:\n",
    "#             fixation_dialog.append(fixation_participant)\n",
    "#             fixation_participant = []\n",
    "#             fixation_frame = []\n",
    "#             fixation_frame.append(fixation_value)\n",
    "#         else:  #count_br == 4\n",
    "#             fixation_points_per_participant_per_frame.append(fixation_dialog)\n",
    "#             fixation_dialog = []\n",
    "#             fixation_participant = []\n",
    "#             fixation_frame = []\n",
    "#             fixation_frame.append(fixation_value)\n",
    "#     fixation_points_per_participant_per_frame.append(fixation_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_points_per_participant_per_frame = pd.read_pickle(r'fixation_points_per_participant_per_frame.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I can compute the dispersion for each frame in each dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_nb = 0\n",
    "dispersion_per_frame = []\n",
    "for dialog in fixation_points_per_frame:\n",
    "    dialog_nb = dialog_nb+1\n",
    "    print(\"Current analysis of dispersion in dialog \"+str(dialog_nb))\n",
    "    dispersion_dialog = []\n",
    "    for frame in dialog:\n",
    "        if len(frame)>1:\n",
    "            for i in frame:\n",
    "                dispersion_values = []\n",
    "                for j in frame:\n",
    "                    if i!=j:\n",
    "                        point_i = np.array(i)\n",
    "                        point_j = np.array(j)\n",
    "                        dist = np.linalg.norm(point_j-point_i) #operate 41 times\n",
    "                        dispersion_values.append(dist)\n",
    "            dispersion = np.sum(dispersion_values)/((len(frame)-1)*len(frame))\n",
    "            dispersion_dialog.append(dispersion)\n",
    "        else:\n",
    "            dispersion_dialog.append(0)\n",
    "    dispersion_per_frame.append(dispersion_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispersion_per_frame.to_pickle('dispersion_per_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dispersion_per_frame[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_per_frame[5][-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export dispersion per frame to csv for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialog_nb = 0\n",
    "# for item_name in fixations_original_all.index.unique():\n",
    "#     df = pd.DataFrame(dispersion_per_frame[dialog_nb],columns=[item_name])\n",
    "#     df.to_csv(item_name+'_dispersion_per_frame_original_all.csv', index=False)\n",
    "#     dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_original_all.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dispersion per from\n",
    "dispersion_per_frame = []\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    dispersion_per_frame.append(pd.read_csv('./results/dispersions_per_frame/original/' + item_name+'_dispersion_per_frame_original_all.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_per_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I plot the dispersion over time for each dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing dispersion value with previous frame value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in dispersion_per_frame:\n",
    "    if 0 in dialog:\n",
    "        dialog_array = np.array(dialog)\n",
    "        ids_zero = np.where(dialog_array == 0)[0]\n",
    "        for id_zero in ids_zero:\n",
    "            if id_zero != 0:\n",
    "                dialog[id_zero] = dialog[id_zero-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create points where x = start time in ms of a frame and y = its corresponding dispersion value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_time = round(1000 / 25)\n",
    "dialog_nb = 0\n",
    "list_points_dialog_disp = []\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    list_points = []\n",
    "    for frame_nb in range(0, round(dialog_durations[[item_name]].values.item() / frame_time)):\n",
    "        frame_begin = frame_nb * frame_time\n",
    "        try:\n",
    "#             disp_value = dispersion_per_frame[dialog_nb][frame_nb]\n",
    "            disp_value = dispersion_per_frame[dialog_nb].loc[frame_nb].values[0]\n",
    "            point = [frame_begin, disp_value]\n",
    "            list_points.append(point)\n",
    "        except: #modified, the original one does not have problems\n",
    "            print(\"dialog: \" + str(dialog_nb) + \" ;frame: \" + str(frame_nb) + \" value is not valid\")\n",
    "#             print(dispersion_per_frame[dialog_nb][frame_nb])\n",
    "\n",
    "    list_points_dialog_disp.append(list_points)\n",
    "    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_per_frame[0].loc[0].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_points_dialog_disp[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_start = 1\n",
    "frame_end = 200\n",
    "\n",
    "selected_dialogs = [3,4,6]\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Dispersion over time for auditive conditions without mask (frame '+str(frame_start)+' to '+str(frame_end)+')')\n",
    "for i in selected_dialogs:\n",
    "    x = [point[0] for point in list_points_dialog_disp[i-1][frame_start:frame_end]]\n",
    "    y = [point[1] for point in list_points_dialog_disp[i-1][frame_start:frame_end]]\n",
    "    if i == 6:\n",
    "        plt.plot(x, y, label='mono', marker='o', color='c')\n",
    "    elif i == 4:\n",
    "        plt.plot(x, y, label='binaural-with-head-rotations', marker='x', color='r')\n",
    "    elif i == 3:\n",
    "        plt.plot(x, y, label='binaural', marker='^', color='g')\n",
    "plt.xlabel('Time in ms')\n",
    "plt.ylabel('Dispersion')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('dispersion.png')\n",
    "\n",
    "selected_dialogs = [1,2,5]\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Dispersion over time for auditive conditions with mask (frame '+str(frame_start)+' to '+str(frame_end)+')')\n",
    "for i in selected_dialogs:\n",
    "    x = [point[0] for point in list_points_dialog_disp[i-1][frame_start:frame_end]]\n",
    "    y = [point[1] for point in list_points_dialog_disp[i-1][frame_start:frame_end]]\n",
    "    if i == 1:\n",
    "        plt.plot(x, y, label='mono_mask', marker='o', color='c')\n",
    "    elif i == 2:\n",
    "        plt.plot(x, y, label='head_mask', marker='x', color='r')\n",
    "    elif i == 5:\n",
    "        plt.plot(x, y, label='spatial_mask', marker='^', color='g')\n",
    "plt.xlabel('Time in ms')\n",
    "plt.ylabel('Dispersion')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('dispersion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean dispersion per condition (real analysis on SPSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion = {}\n",
    "dialog_nb = 0\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    mean_dispersion[item_name] = np.mean(dispersion_per_frame[dialog_nb])\n",
    "    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I measure the distance of the fixations to the center for each frame. To do so, I use the fixation points of each frame and compute their centroid. Then I compute the distance of the centroid to the center of the image (640, 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(fixation_points_per_frame[0][0]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_center_per_frame = []\n",
    "centroid_per_frame = []\n",
    "center = np.array([640,360])\n",
    "dialog_nb = 0\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    dist_values = []\n",
    "    centroid_dialog = []\n",
    "    for frame in fixation_points_per_frame[dialog_nb]:\n",
    "        arr = np.array(frame)\n",
    "        length = arr.shape[0]\n",
    "        if length > 1:\n",
    "            sum_x = np.sum(arr[:, 0])\n",
    "            sum_y = np.sum(arr[:, 1])\n",
    "            centroid = np.array([sum_x/length, sum_y/length])\n",
    "            dist = np.linalg.norm(centroid-center)\n",
    "            dist_values.append(dist)\n",
    "            centroid_dialog.append(centroid)\n",
    "        else:\n",
    "            dist_values.append(0)\n",
    "            centroid_dialog.append(np.array([640,360]))\n",
    "    dist_center_per_frame.append(dist_values)\n",
    "    centroid_per_frame.append(centroid_dialog)\n",
    "    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist_center_per_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I export this to csv per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialog_nb = 0\n",
    "#for item_name in fixations_original_all.index.unique():\n",
    "#    df = pd.DataFrame(dist_center_per_frame[dialog_nb],columns=[item_name])\n",
    "#    df.to_csv(item_name+'_distance_center_per_frame_original_all.csv', index=False)\n",
    "#    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then I plot the distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing distance value with previous frame value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dialog in dist_center_per_frame:\n",
    "#    if 0 in dialog:\n",
    "#        dialog_array = np.array(dialog)\n",
    "#        ids_zero = np.where(dialog_array == 0)[0]\n",
    "#        for id_zero in ids_zero:\n",
    "#            if id_zero != 0:\n",
    "#                dialog[id_zero] = dialog[id_zero-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create points where x = start time in ms of a frame and y = its corresponding distance to center value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_time = round(1000 / 25)\n",
    "dialog_nb = 0\n",
    "list_points_dialog_center = []\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    list_points = []\n",
    "    for frame_nb in range(0, round(dialog_durations[[item_name]].values.item() / frame_time)):\n",
    "        frame_begin = frame_nb * frame_time\n",
    "        dist_value = dist_center_per_frame[dialog_nb][frame_nb]\n",
    "        point = [frame_begin, dist_value]\n",
    "        list_points.append(point)\n",
    "    list_points_dialog_center.append(list_points)\n",
    "    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_points_dialog_center[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_start = 1\n",
    "frame_end = 2000\n",
    "\n",
    "selected_dialogs = [3,4,6]\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Distance to center over time for auditive conditions without mask (frame '+str(frame_start)+' to '+str(frame_end)+')')\n",
    "for i in selected_dialogs:\n",
    "    x = [point[0] for point in list_points_dialog_center[i-1][frame_start:frame_end]]\n",
    "    y = [point[1] for point in list_points_dialog_center[i-1][frame_start:frame_end]]\n",
    "    if i == 6:\n",
    "        plt.plot(x, y, label='mono', marker='o', color='c')\n",
    "    elif i == 4:\n",
    "        plt.plot(x, y, label='head', marker='x', color='r')\n",
    "    elif i == 3:\n",
    "        plt.plot(x, y, label='spatial', marker='^', color='g')\n",
    "plt.xlabel('Time in ms')\n",
    "plt.ylabel('Distance to center')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('dispersion.png')\n",
    "\n",
    "selected_dialogs = [1,2,5]\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Distance to center over time for auditive conditions with mask (frame '+str(frame_start)+' to '+str(frame_end)+')')\n",
    "for i in selected_dialogs:\n",
    "    x = [point[0] for point in list_points_dialog_center[i-1][frame_start:frame_end]]\n",
    "    y = [point[1] for point in list_points_dialog_center[i-1][frame_start:frame_end]]\n",
    "    if i == 1:\n",
    "        plt.plot(x, y, label='mono_mask', marker='o', color='c')\n",
    "    elif i == 2:\n",
    "        plt.plot(x, y, label='head_mask', marker='x', color='r')\n",
    "    elif i == 5:\n",
    "        plt.plot(x, y, label='spatial_mask', marker='^', color='g')\n",
    "plt.xlabel('Time in ms')\n",
    "plt.ylabel('Distance to center')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('dispersion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean distance to center per condition (real analysis on SPSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_center_dist = {}\n",
    "dialog_nb = 0\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    mean_center_dist[item_name] = np.mean(dist_center_per_frame[dialog_nb])\n",
    "    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_center_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Areas of interest and Scanpaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set AoI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data, obtained with standard webcam, are not of high quality. Thus when the participants look at a specific location, the measured gaze data might have some offsets from this location (even if a calibration was made beforehand). Actually a study made by the provider of the eye-tracking solution we used resulted in an average spatial accuracy of their system of 113px. This means that if I want to set AoIs I have to take this into account and I can't draw a precise area. Instead, I draw a subjective global area around the body of the actors and I name them: L,F,R (L for left actor, R for right actor and F for front actor). Let's draw the areas (the areas will be the same for every dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacking screenshot of dialogs\n",
    "list_screenshots = [\n",
    "    cv2.imread(\"./screenshot/dialog\"+str(i)+\"_screenshot.png\") for i in range(1,7)]\n",
    "list_screenshots = [\n",
    "    cv2.cvtColor(list_screenshots[i],cv2.COLOR_BGR2RGB) for i in range(0,6)\n",
    "]\n",
    "dialog1_screenshot, dialog2_screenshot, dialog3_screenshot, dialog4_screenshot, dialog5_screenshot, dialog6_screenshot = [\n",
    "    np.copy(list_screenshots[i]) for i in range(0,6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L= [(125,313),(477,681)]\n",
    "R= [(906,303),(1226,683)]\n",
    "F= [(559,179),(830,444)]\n",
    "color_red = (255,0,0) #red color\n",
    "color_orange = (235, 155, 52)\n",
    "color_green = (87, 163, 75)\n",
    "thick = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "plt.box(False)\n",
    "for image in list_screenshots:\n",
    "   \n",
    "    plt.figure(figsize=(12.8, 7.2), dpi=100)\n",
    "    \n",
    "    plt.title(\"Dialog \"+str(i))\n",
    "    screenshot = np.copy(image)\n",
    "    screenshot = cv2.rectangle(screenshot,L[0],L[1],color_red, thick)\n",
    "    screenshot = cv2.rectangle(screenshot,R[0],R[1],color_green, thick)\n",
    "    screenshot = cv2.rectangle(screenshot,F[0],F[1],color_orange, thick)\n",
    "    \n",
    "    plt.imshow(screenshot)\n",
    "    \n",
    "    fig.savefig(\"./screenshot/aoi_screenshot/aoi_dialog\"+str(i)+\".png\", bbox_inches='tight')\n",
    "\n",
    "#     plt.savefig(\"./screenshot/aoi_screenshot/aoi_dialog\"+str(i)+\".png\", bbox_inches='tight')\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation of distance to center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = [640,360]\n",
    "for i, image in enumerate(list_screenshots):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title(\"Dialog \"+str(i+1))\n",
    "    screenshot = np.copy(image)\n",
    "    list_dialogs= dialog_durations.columns.tolist()\n",
    "    dialog_name = list_dialogs[i]\n",
    "    for frame_nb in range(0, round(dialog_durations[[dialog_name]].values.item() / frame_time)):\n",
    "        point = centroid_per_frame[i][frame_nb]\n",
    "        x = [point[0],center[0]]\n",
    "        y = [point[1],center[1]]\n",
    "        plt.plot(x,y)\n",
    "    plt.imshow(screenshot)\n",
    "    #plt.show()\n",
    "    #plt.savefig('dist_center_dialog_'+str(i+1)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation of centroid distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = [640,360]\n",
    "for i, image in enumerate(list_screenshots):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title(\"Dialog \"+str(i+1))\n",
    "    screenshot = np.copy(image)\n",
    "    list_dialogs= dialog_durations.columns.tolist()\n",
    "    dialog_name = list_dialogs[i]\n",
    "    x = []\n",
    "    y = []\n",
    "    for frame_nb in range(0, round(dialog_durations[[dialog_name]].values.item() / frame_time)):\n",
    "        point = centroid_per_frame[i][frame_nb]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "    d = {'x':x, 'y':y}\n",
    "    pdxy = pd.DataFrame(d)\n",
    "    #plt.scatter(x,y)\n",
    "    #plt.hist2d(x, y, bins=50, cmap=plt.cm.jet, cmin=1, alpha=0.5)\n",
    "    hmax= sns.kdeplot(pdxy['x'], pdxy['y'], cmap=\"Reds\", shade=True, alpha=0.7)\n",
    "    hmax.collections[0].set_alpha(0)\n",
    "    plt.imshow(screenshot,origin='upper')\n",
    "    #plt.show()\n",
    "    #plt.savefig('centroid_distribution_dialog_'+str(i+1)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation of space-time cube (fixations points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_nb, dialog in enumerate(fixation_points_per_frame):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for frame_nb, frame in enumerate(dialog):\n",
    "        if(len(frame)>0):\n",
    "            for point in frame:\n",
    "                x.append(point[0])\n",
    "                y.append(point[1])\n",
    "                z.append(frame_nb)\n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    ax = plt.axes(projection =\"3d\")\n",
    "    ax.set_xlim(1280,0)\n",
    "    ax.set_ylim(0,720)\n",
    "    ax.set_zlim(0,max(z))\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"frames\")\n",
    "    ax.scatter3D(np.array(x), np.array(y), np.array(z), color = \"red\")\n",
    "    plt.title(\"3D representation of fixations points in dialog \"+str(dialog_nb+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation of space-time cube (scanpath, unit=frame, no generalization on AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_nb, dialog in enumerate(fixation_points_per_participant_per_frame):\n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    ax = plt.axes(projection =\"3d\")\n",
    "    plt.title(\"3D representation of scanpath in dialog \"+str(dialog_nb+1))\n",
    "    #for i in range (0,2):\n",
    "    participant = dialog[1]\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for frame_nb, frame in enumerate(participant):\n",
    "        if(len(frame)>0):\n",
    "            for point in frame:\n",
    "                x.append(point[0])\n",
    "                y.append(point[1])\n",
    "                z.append(frame_nb)\n",
    "    ax.set_xlim(1280,0)\n",
    "    ax.set_ylim(0,720)\n",
    "    ax.set_zlim(0,max(z))\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"frames\")\n",
    "    ax.plot3D(np.array(x), np.array(y), np.array(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dialog[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_frame_count = 0\n",
    "for frame_nb, frame in enumerate(participant):\n",
    "    if not frame:\n",
    "        empty_frame_count = empty_frame_count + 1\n",
    "print(empty_frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# import numpy as np\n",
    "# im = plt.imshow(np.flipud(plt.imread('./screenshot/dialog5_screenshot.png')), origin='lower')\n",
    "# plt.show()\n",
    "# image = mpimg.imread('./screenshot/dialog5_screenshot.png')\n",
    "# plt.imshow(image)  \n",
    "image = list_screenshots[4]\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Dialog \"+str(5))\n",
    "screenshot = np.copy(image)\n",
    "screenshot = cv2.rectangle(screenshot,L[0],L[1],color_red, thick)\n",
    "screenshot = cv2.rectangle(screenshot,R[0],R[1],color_green, thick)\n",
    "screenshot = cv2.rectangle(screenshot,F[0],F[1],color_orange, thick)\n",
    "plt.imshow(screenshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib._png import read_png\n",
    "from matplotlib.cbook import get_sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# demo period\n",
    "\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "dialog_nb = 4\n",
    "dialog = fixation_points_per_participant_per_frame[dialog_nb]\n",
    "\n",
    "frame_start = 2051\n",
    "frame_end = 2177\n",
    "\n",
    "# ax = plt.axes(projection =\"3d\")\n",
    "plt.title(\"3D representation of scanpath of each partcipant in dialog \"+str(dialog_nb+1) + \n",
    "          \" of frame:\" + str(frame_start) + \" to \" + str(frame_end))\n",
    "\n",
    "# plot image\n",
    "img = read_png('./screenshot/dialog1_screenshot.png')\n",
    "x, y = np.ogrid[0:img.shape[0], 0:img.shape[1]]\n",
    "ax.plot_surface(x, y, np.atleast_2d(frame_start), rstride=8, cstride=8, facecolors=img, alpha=0.2)\n",
    "\n",
    "\n",
    "# plot scanpath\n",
    "for i in range (0,42): # loop through 42 participantw\n",
    "    participant = dialog[i]\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for frame_nb in range(frame_start-1, frame_end):\n",
    "        if participant[frame_nb] != []:\n",
    "            x.append(participant[frame_nb][0][1])\n",
    "            y.append(participant[frame_nb][0][0])\n",
    "            z.append(frame_nb)\n",
    "\n",
    "    ax.set_xlim(0,720)\n",
    "    ax.set_ylim(0,1280)\n",
    "    ax.set_zlim(frame_start,frame_end)\n",
    "\n",
    "    ax.set_xlabel(\"y\")\n",
    "    ax.set_ylabel(\"x\")\n",
    "    ax.set_zlabel(\"frames\")\n",
    "    \n",
    "    ax.plot3D(np.array(x), np.array(y), np.array(z), c='royalblue')\n",
    "    \n",
    "ax.view_init(elev=25, azim=-15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_of_interest = ['L','R','F','e']\n",
    "aoi_ratio_normal_transitions = {}\n",
    "dialog_nb = 4\n",
    "aoi_ratio_normal_transitions[dialog_nb] = {}\n",
    "\n",
    "frame_start = 2109 - 25\n",
    "frame_end = 2119 + 25\n",
    "if frame_start < 0:\n",
    "    frame_start = 0\n",
    "if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "    frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.title('Fixation ratios on AoIs over frames for dialog '+str(dialog_nb+1)+' (window frames: '+str(frame_start)+' to '+str(frame_end)+') (transition frames: '+str(dialog_normal_transitions[dialog_nb][window_nb][0])+' to '+str(dialog_normal_transitions[dialog_nb][window_nb][1])+')'\n",
    "         + '. Silence is marked in orange.' \n",
    "         )\n",
    "for i in areas_of_interest:\n",
    "    aoi_ratio_normal_transitions[dialog_nb][window_nb][i] = []\n",
    "    x = []\n",
    "    y = []\n",
    "    for frame in range(frame_start-1, frame_end):\n",
    "        x.append(frame)\n",
    "        y.append(aoi_ratios_per_frame[list(aoi_ratios_per_frame.keys())[dialog_nb]][frame][i])\n",
    "        aoi_ratio_normal_transitions[dialog_nb][window_nb][i].append(y)\n",
    "    if i == 'L':\n",
    "        plt.plot(x, y, label='left', marker='o', color='r')\n",
    "    elif i == 'R':\n",
    "        plt.plot(x, y, label='right', marker='x', color='g')\n",
    "    elif i == 'F':\n",
    "        plt.plot(x, y, label='front', marker='^', color='orange')\n",
    "    else:\n",
    "        plt.plot(x, y, label='exterior', marker='+', color='gray')\n",
    "\n",
    "plt.axvspan(dialog_normal_transitions[dialog_nb][window_nb][0], dialog_normal_transitions[dialog_nb][window_nb][1], color='bisque', alpha=0.4) ## highlight silent area       \n",
    "\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Fixation ratio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dialog_nb, dialog in enumerate(fixation_points_per_participant_per_frame):\n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    ax = plt.axes(projection =\"3d\")\n",
    "    plt.title(\"3D representation of scanpath in dialog \"+str(dialog_nb+1))\n",
    "    for i in range (0,42):\n",
    "        participant = dialog[i]\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        for frame_nb, frame in enumerate(participant):\n",
    "            if(len(frame)>0):\n",
    "                for point in frame:\n",
    "                    x.append(point[0])\n",
    "                    y.append(point[1])\n",
    "                    z.append(frame_nb)\n",
    "        ax.set_xlim(1280,0)\n",
    "        ax.set_ylim(0,720)\n",
    "        ax.set_zlim(0,max(z))\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"y\")\n",
    "        ax.set_zlabel(\"frames\")\n",
    "        ax.plot3D(np.array(x), np.array(y), np.array(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Scanpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function to check if a point is in an area of interest (rect) or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointInRect(point,rect):\n",
    "    x1, y1, x2, y2 = rect\n",
    "    x, y = point\n",
    "    if (x1 <= x and x <= x2):\n",
    "        if (y1 <= y and y <= y2):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now compute a scanpath for every participant in each condition. If the fixation point is in the AoI, I add the corresponding letter of the AoI to the scanpath, otherwise we add the character 'e' which means that the point is in none of the AoIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, first I attribute an area of interest letter to every fixation point in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_list = []\n",
    "\n",
    "points_list = list(zip(fixations_original_all.fixation_point_x.tolist(), fixations_original_all.fixation_point_y.tolist()))\n",
    "L_rect = [L[0][0], L[0][1], L[1][0], L[1][1]]\n",
    "R_rect = [R[0][0], R[0][1], R[1][0], R[1][1]]\n",
    "F_rect = [F[0][0], F[0][1], F[1][0], F[1][1]]\n",
    "\n",
    "for point in points_list:\n",
    "    if pointInRect(point, L_rect):\n",
    "        aoi_list.append('L')\n",
    "    elif pointInRect(point, R_rect):\n",
    "        aoi_list.append('R')\n",
    "    elif pointInRect(point, F_rect):\n",
    "        aoi_list.append('F')\n",
    "    else:\n",
    "        aoi_list.append('e')\n",
    "        \n",
    "fixations_and_aoi = fixations_original_all.copy()\n",
    "fixations_and_aoi['aoi'] = aoi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_and_aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixations_and_aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_and_aoi.index.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I regroup all the characters together in a string for every participant in each dialog. (index is PID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_scanpaths = []\n",
    "for part_id in range(len(fixations_and_aoi.tester_id.unique())):\n",
    "    scanpaths = []\n",
    "    for item_name in fixations_and_aoi.index.unique():\n",
    "        string_path = \"\"\n",
    "        string_path = string_path.join(fixations_and_aoi.loc[\n",
    "            (fixations_and_aoi.index ==item_name) \n",
    "            & (fixations_and_aoi.tester_id == part_id), 'aoi'].tolist())\n",
    "        scanpaths.append(string_path)\n",
    "    participant_scanpaths.append(scanpaths)\n",
    "participant_scanpaths = pd.DataFrame(participant_scanpaths, columns=fixations_original_all.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_scanpaths.to_csv('long_scanpaths.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_scanpaths = pd.read_csv(\"./results/scanpaths/long_scanpaths.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create scanpath per participant per "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify individual scanpaths by abstracting consecutive repetitions (used later for calculating the number of transitions) (ratio with the number of speech acts in each videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_scanpaths = []\n",
    "for i in range(0, 42):\n",
    "    list_paths = []\n",
    "    for column in participant_scanpaths:\n",
    "        item = participant_scanpaths[column][i]\n",
    "        path = ''.join(i for i, _ in itertools.groupby(item))\n",
    "        list_paths.append(path)\n",
    "    short_scanpaths.append(list_paths)\n",
    "short_scanpaths = pd.DataFrame(short_scanpaths, columns=fixations_original_all.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#short_scanpaths.to_csv('short_scanpaths.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Dissimilarity with Dynamic Time Warping (DTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the Dynamic Time Warping alogrithm (from tslearn) which aligns two sequences along a common time axis by considering only substitutions (the sequences do not need to be align on the same time points beforehands). With it I can compute the dissimilarity between two scanpaths. I use a sakoe chiba band of radius 1 and a predefined cost function (cost of 1 for all difference). It is not required that both time series share the same size, but they must be the same dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this I first need to transform my scanpaths into numerical values. I will therefore attribute the value 0 to 'e', 1 to 'R', 2 to 'F' and 3 to 'L'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in participant_scanpaths:\n",
    "    print(dialog)\n",
    "    for index, path in enumerate(participant_scanpaths[dialog]):\n",
    "        print(index)\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_scanpaths = {}\n",
    "for dialog in participant_scanpaths:\n",
    "    num_scanpaths[dialog] = {}\n",
    "    for index, path in enumerate(participant_scanpaths[dialog]):\n",
    "        num_path = [0 if element == 'e' else 1 if element == 'R' else 2 if element == 'F' else 3 if element == 'L' else element for element in path]\n",
    "        num_scanpaths[dialog][index] = num_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plot here a visualization of the scanpath between the different area of interest that I have set (the x-axis is simply the length of the scanpaths, it is not the actual duration of the fixation point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "y = num_scanpaths['dialog3_spatial'][2]\n",
    "x = [i for i,value in enumerate(y)]\n",
    "\n",
    "plt.hlines(3, 0, len(x)-1, colors='red', linestyles='solid', label='Left')\n",
    "plt.hlines(2, 0, len(x)-1, colors='orange', linestyles='solid', label='Front')\n",
    "plt.hlines(1, 0, len(x)-1, colors='green', linestyles='solid', label='Right')\n",
    "plt.hlines(0, 0, len(x)-1, colors='black', linestyles='solid', label='Exterior')\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Number of fixations')\n",
    "plt.title('Visualization of the scanpath of participant 3 in dialog 3.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fct(x,y):\n",
    "    if x != y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment the next line to execute this cell\n",
    "%%script false --no-raise-error\n",
    "dissimilarity_results = {}\n",
    "for dialog in num_scanpaths:\n",
    "    dissimilarity_results[dialog] = {}\n",
    "    for index1 in num_scanpaths[dialog]:\n",
    "        dissimilarity_results[dialog][index1] = {}\n",
    "        for index2 in num_scanpaths[dialog]:\n",
    "            if index1 != index2:\n",
    "                match, dissimilarity = dtw_path_from_metric(num_scanpaths[dialog][index1],\n",
    "                                    num_scanpaths[dialog][index2],\n",
    "                                    metric=cost_fct,\n",
    "                                    global_constraint = \"sakoe_chiba\",\n",
    "                                    sakoe_chiba_radius=1\n",
    "                                   )\n",
    "                dissimilarity_results[dialog][index1][index2] = dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store dissimilarity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r dissimilarity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I compute the mean dissimilarity of all participant between the all the other for each dialog. This will allow to then compute a mean dissimilarity over all participants and in the end indicate quantitatively how much the participants had a similar visual behaviour (low value indicate more similar behaviour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dissimilarity = {}\n",
    "for dialog in dissimilarity_results:\n",
    "    mean_dissimilarity[dialog] = {}\n",
    "    for part_id in dissimilarity_results[dialog]:\n",
    "        mean_dissimilarity[dialog][part_id] = np.mean(list(dissimilarity_results[dialog][part_id].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dissimilarity = pd.DataFrame(mean_dissimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dissimilarity_sorted = pd.DataFrame(np.sort(mean_dissimilarity.values, axis=0), index=mean_dissimilarity.index, columns=mean_dissimilarity.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_dissimilarity.to_csv('mean_dissimilarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dissimilarity_dialog = {}\n",
    "for dialog in mean_dissimilarity:\n",
    "    mean_dissimilarity_dialog[dialog]=np.mean(mean_dissimilarity[dialog].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dissimilarity_dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AoIs Fixation ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each frame, we can compute the ratio of each AoI (number of fixation points in the AoI divided by the number of fixation points in the frame). For this I first again regroup the fixation points by frame, with their corresponding AoI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment the next line to execute this cell\n",
    "%%script false --no-raise-error\n",
    "# structure : \n",
    "# first level = dialog1, dialog2, ...\n",
    "# second level = frame 1, frame 2, ... \n",
    "# third level = fixation point 1, fixation point 2, ..\n",
    "frame_time = round(1000 / 25)\n",
    "aoi_per_frame = {}\n",
    "for item_name in fixations_and_aoi.index.unique(): # each dialog\n",
    "    aoi_per_frame[item_name] = {}\n",
    "    for frame_nb in range(0, round(dialog_durations[[item_name]].values.item() / frame_time)): #each frame\n",
    "        frame_begin = frame_nb * frame_time\n",
    "        frame_end = (frame_nb+1) * frame_time\n",
    "        list_points_frame = fixations_and_aoi.loc[\n",
    "                (fixations_and_aoi.index == item_name)\n",
    "                & (\n",
    "                    (\n",
    "                        (fixations_and_aoi.fixation_starts_at_ms >= frame_begin) \n",
    "                        & (fixations_and_aoi.fixation_starts_at_ms < frame_end)\n",
    "                        & (fixations_and_aoi.fixation_ends_at_ms > frame_end)\n",
    "                    ) |\n",
    "                    (\n",
    "                        (fixations_and_aoi.fixation_starts_at_ms <= frame_begin)\n",
    "                        & (fixations_and_aoi.fixation_ends_at_ms > frame_begin )\n",
    "                        & (fixations_and_aoi.fixation_ends_at_ms < frame_end )\n",
    "                    ) |\n",
    "                    (\n",
    "                        (fixations_and_aoi.fixation_starts_at_ms >= frame_begin)\n",
    "                        & (fixations_and_aoi.fixation_starts_at_ms < frame_end)\n",
    "                        & (fixations_and_aoi.fixation_ends_at_ms > frame_begin)\n",
    "                        & (fixations_and_aoi.fixation_ends_at_ms < frame_end)\n",
    "                    ) |\n",
    "                    (\n",
    "                        (fixations_and_aoi.fixation_starts_at_ms <= frame_begin)\n",
    "                        & (fixations_and_aoi.fixation_ends_at_ms >= frame_end)\n",
    "                    ) \n",
    "                  ),\n",
    "                \"aoi\"].values.tolist()\n",
    "        aoi_per_frame[item_name][frame_nb] = list_points_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store aoi_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r aoi_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_per_frame = pd.read_pickle(r'aoi_per_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "aoi_ratios_per_frame = {}\n",
    "for dialog in aoi_per_frame:\n",
    "    aoi_ratios_per_frame[dialog] = {}\n",
    "    for frame in aoi_per_frame[dialog]:\n",
    "        aoi_ratios_per_frame[dialog][frame] = {}\n",
    "        length = len(aoi_per_frame[dialog][frame])\n",
    "        if length > 0 :\n",
    "            aoi_ratios_per_frame[dialog][frame]['L'] = aoi_per_frame[dialog][frame].count('L')/length\n",
    "            aoi_ratios_per_frame[dialog][frame]['R'] = aoi_per_frame[dialog][frame].count('R')/length\n",
    "            aoi_ratios_per_frame[dialog][frame]['F'] = aoi_per_frame[dialog][frame].count('F')/length\n",
    "            aoi_ratios_per_frame[dialog][frame]['e'] = aoi_per_frame[dialog][frame].count('e')/length\n",
    "            # find the most frequent area\n",
    "            dict_temp = dict((k, aoi_ratios_per_frame[dialog][frame][k]) for k in ('L', 'R', 'F', 'e'))\n",
    "            dict_temp_note_e = dict((k, aoi_ratios_per_frame[dialog][frame][k]) for k in ('L', 'R', 'F'))\n",
    "            \n",
    "            aoi_ratios_per_frame[dialog][frame]['aoi_most'] = max(dict_temp.items(), key=operator.itemgetter(1))[0]\n",
    "            aoi_ratios_per_frame[dialog][frame]['aoi_most_not_e'] = max(dict_temp_note_e.items(), key=operator.itemgetter(1))[0]\n",
    "        else:\n",
    "            aoi_ratios_per_frame[dialog][frame]['L'] = 0\n",
    "            aoi_ratios_per_frame[dialog][frame]['R'] = 0\n",
    "            aoi_ratios_per_frame[dialog][frame]['F'] = 0\n",
    "            aoi_ratios_per_frame[dialog][frame]['e'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_ratios_per_frame['dialog1_normal_mask'][26][aoi_ratios_per_frame['dialog1_normal_mask'][26]['aoi_most']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_ratios_per_frame['dialog1_normal_mask'][27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store aoi_ratios_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(aoi_ratios_per_frame['dialog1_normal_mask'][1]['aoi_most_not_e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the genetic scan with respect to frame (the area with the max no. of AOI is consider the AOI of the frame). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include exterior (e)\n",
    "num_scanpaths_aoi = {}\n",
    "for dialog in aoi_ratios_per_frame:\n",
    "    num_scanpaths_aoi[dialog] = {}\n",
    "    num_path_aoi = []\n",
    "    for frame in aoi_ratios_per_frame[dialog]:\n",
    "        try:\n",
    "            aoi_most_temp = str(aoi_ratios_per_frame[dialog][frame]['aoi_most'])\n",
    "    #         print(aoi_most_temp)\n",
    "    #         print('\\n')\n",
    "            if aoi_most_temp == 'e': \n",
    "                num_path_aoi.append(0)\n",
    "            elif aoi_most_temp == 'R':\n",
    "                num_path_aoi.append(1)\n",
    "            elif aoi_most_temp == 'F':\n",
    "                num_path_aoi.append(2)\n",
    "            else: # 'L'\n",
    "                num_path_aoi.append(3)\n",
    "        except:\n",
    "            num_path_aoi.append(None) # no AOI in this frame\n",
    "            print('dialog: ' + dialog + ' frame:' + str(frame))\n",
    "    num_scanpaths_aoi[dialog] = num_path_aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude exterior (e)\n",
    "num_scanpaths_aoi_not_e = {}\n",
    "for dialog in aoi_ratios_per_frame:\n",
    "    num_scanpaths_aoi_not_e[dialog] = {}\n",
    "    num_path_aoi_not_e = []\n",
    "    for frame in aoi_ratios_per_frame[dialog]:\n",
    "        try:\n",
    "            aoi_most_temp_not_e = str(aoi_ratios_per_frame[dialog][frame]['aoi_most_not_e'])        \n",
    "#             if aoi_most_temp == 'e': \n",
    "#                 num_path_aoi.append(0)\n",
    "            if aoi_most_temp_not_e == 'R':\n",
    "                num_path_aoi_not_e.append(1)\n",
    "            elif aoi_most_temp_not_e == 'F':\n",
    "                num_path_aoi_not_e.append(2)\n",
    "            else: # 'L'\n",
    "                num_path_aoi_not_e.append(3)\n",
    "        except:\n",
    "            num_path_aoi_not_e.append(None) # no AOI in this frame\n",
    "            print('dialog: ' + dialog + ' frame:' + str(frame))\n",
    "    num_scanpaths_aoi_not_e[dialog] = num_path_aoi_not_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)\n",
    "\n",
    "# 'dialog1_normal_mask': 122.24622531939605,\n",
    "#  'dialog2_head_mask': 102.22299651567945,\n",
    "#  'dialog3_spatial': 98.13356562137051,\n",
    "#  'dialog4_head': 95.56329849012775,\n",
    "#  'dialog5_spatial_mask': 94.78281068524971,\n",
    "#  'dialog6_normal': 110.77700348432056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include exterior (e) \n",
    "for dialog in aoi_ratios_per_frame:\n",
    "\n",
    "    plt.figure(figsize=(20,4))\n",
    "    y = num_scanpaths_aoi[dialog]\n",
    "    x = [i for i,value in enumerate(y)]\n",
    "\n",
    "    plt.hlines(3, 0, len(x)-1, colors='red', linestyles='solid', label='Left')\n",
    "    plt.hlines(2, 0, len(x)-1, colors='orange', linestyles='solid', label='Front')\n",
    "    plt.hlines(1, 0, len(x)-1, colors='green', linestyles='solid', label='Right')\n",
    "    plt.hlines(0, 0, len(x)-1, colors='black', linestyles='solid', label='Exterior')\n",
    "\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('Frames')\n",
    "    plt.title('Visualization of the genetic scanpath in '+ dialog)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude exterior (e)\n",
    "for dialog in aoi_ratios_per_frame:\n",
    "\n",
    "    plt.figure(figsize=(20,4))\n",
    "    y = num_scanpaths_aoi_not_e[dialog]\n",
    "    x = [i for i,value in enumerate(y)]\n",
    "\n",
    "    plt.hlines(3, 0, len(x)-1, colors='red', linestyles='solid', label='Left')\n",
    "    plt.hlines(2, 0, len(x)-1, colors='orange', linestyles='solid', label='Front')\n",
    "    plt.hlines(1, 0, len(x)-1, colors='green', linestyles='solid', label='Right')\n",
    "#     plt.hlines(0, 0, len(x)-1, colors='black', linestyles='solid', label='Exterior')\n",
    "\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('Frames')\n",
    "    plt.title('Visualization of the genetic scanpath in '+ dialog + \" excluding exterior\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude exterior (e)\n",
    "for dialog in aoi_ratios_per_frame:\n",
    "\n",
    "    plt.figure(figsize=(20,4))\n",
    "    y = num_scanpaths_aoi_not_e[dialog]\n",
    "    x = [i for i,value in enumerate(y)]\n",
    "\n",
    "    plt.hlines(3, 0, len(x)-1, colors='red', linestyles='solid', label='Left')\n",
    "    plt.hlines(2, 0, len(x)-1, colors='orange', linestyles='solid', label='Front')\n",
    "    plt.hlines(1, 0, len(x)-1, colors='green', linestyles='solid', label='Right')\n",
    "#     plt.hlines(0, 0, len(x)-1, colors='black', linestyles='solid', label='Exterior')\n",
    "\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('Frames')\n",
    "    plt.title('Visualization of the genetic scanpath in '+ dialog + \" excluding exterior\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now plot the evolution of the fixation ratio on the AoI over the frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aoi_ratios_per_frame['dialog1_normal_mask'][1]['L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_of_interest = ['L','R','F','e']\n",
    "for dialog_nb in range(0,6):\n",
    "    list_dialogs= dialog_durations.columns.tolist()\n",
    "    dialog_name = list_dialogs[dialog_nb]\n",
    "    frame_start = 1\n",
    "    frame_end = int(dialog_durations.iloc[:, [dialog_nb]].values[0]/40)\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.title('Fixation ratios on ROIs over frames in dialog '+str(dialog_nb+1)+' (frame '+str(frame_start)+' to '+str(frame_end)+')')\n",
    "    for i in areas_of_interest:\n",
    "        x = []\n",
    "        y = []\n",
    "        for frame in range(frame_start-1, frame_end):\n",
    "            x.append(frame)\n",
    "            y.append(aoi_ratios_per_frame[dialog_name][frame][i])\n",
    "        if i == 'L':\n",
    "            plt.scatter(x, y, label='left', marker='o', color='r')\n",
    "        elif i == 'R':\n",
    "            plt.scatter(x, y, label='right', marker='x', color='g')\n",
    "        elif i == 'F':\n",
    "            plt.scatter(x, y, label='front', marker='^', color='orange')\n",
    "        else:\n",
    "            plt.scatter(x, y, label='exterior', marker='+', color='black')\n",
    "    plt.xlabel('Frames')\n",
    "    plt.ylabel('Fixation ratio')\n",
    "    plt.legend()\n",
    "    #plt.savefig('aoi_ratio_dialog_'+str(dialog_nb+1)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_of_interest = ['L','R','F','e']\n",
    "for dialog_nb in range(0,6):\n",
    "    list_dialogs= dialog_durations.columns.tolist()\n",
    "    dialog_name = list_dialogs[dialog_nb]\n",
    "    frame_start = 1\n",
    "    frame_end = int(dialog_durations.iloc[:, [dialog_nb]].values[0]/40)\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.title('Fixation ratios on ROIs over frames in dialog '+str(dialog_nb+1)+' (frame '+str(frame_start)+' to '+str(frame_end)+')')\n",
    "    for i in areas_of_interest:\n",
    "        x = []\n",
    "        y = []\n",
    "        for frame in range(frame_start-1, frame_end):\n",
    "            x.append(frame)\n",
    "            y.append(aoi_ratios_per_frame[dialog_name][frame][i])\n",
    "        if i == 'L':\n",
    "            plt.scatter(x, y, label='left', marker='o', color='r')\n",
    "        elif i == 'R':\n",
    "            plt.scatter(x, y, label='right', marker='x', color='g')\n",
    "        elif i == 'F':\n",
    "            plt.scatter(x, y, label='front', marker='^', color='orange')\n",
    "        else:\n",
    "            plt.scatter(x, y, label='exterior', marker='+', color='black')\n",
    "    plt.xlabel('Frames')\n",
    "    plt.ylabel('Fixation ratio')\n",
    "    plt.legend()\n",
    "    #plt.savefig('aoi_ratio_dialog_'+str(dialog_nb+1)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Global analysis) AoI number of fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_nb_fixation = {}\n",
    "for item_name in fixations_and_aoi.index.unique():\n",
    "    aoi_nb_fixation[item_name] = {}\n",
    "    for area_of_interest in fixations_and_aoi.aoi.unique():\n",
    "        nb_fixation = fixations_and_aoi.loc[\n",
    "                (fixations_and_aoi.index == item_name) \n",
    "                & (fixations_and_aoi.aoi == area_of_interest)].shape[0]\n",
    "        aoi_nb_fixation[item_name][area_of_interest] = nb_fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aoi_nb_fixation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Global analysis) AoI mean fixation duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_fixation_dur = {}\n",
    "for item_name in fixations_and_aoi.index.unique():\n",
    "    aoi_fixation_dur[item_name] = {}\n",
    "    for area_of_interest in fixations_and_aoi.aoi.unique():\n",
    "        fix_dur = np.mean(fixations_and_aoi.loc[\n",
    "                (fixations_and_aoi.index == item_name) \n",
    "                & (fixations_and_aoi.aoi == area_of_interest), 'fixation_duration_ms'].to_list())\n",
    "        aoi_fixation_dur[item_name][area_of_interest] = fix_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aoi_fixation_dur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific analysis (on group of frames / event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following I will use some of the previous measure to make an analysis at particular time/event in the videos. First I import the data relative to the events in each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_event = [pd.read_csv('./data/event_timestamp/event_timestamp_dialog'+str(i)+'.csv', sep=';') for i in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_event = ['speaker_left','speaker_right','speaker_front']\n",
    "#columns_name = [\"speaker\",\"event\",\"frame_start\",\"frame_end\"]\n",
    "#for i in range(0,6):\n",
    "#    speaker_list = []\n",
    "#    for event_name in list_event:\n",
    "#        events = dfs_event[i].loc[(dfs_event[i].event == event_name+'_start'), \"key_point\"].to_list()\n",
    "#        frame_start = dfs_event[i].loc[(dfs_event[i].event == event_name+'_start'), \"frame_number\"].to_list()\n",
    "#        frame_end = dfs_event[i].loc[(dfs_event[i].event == event_name+'_stop'), \"frame_number\"].to_list()\n",
    "#        for item_nb in range(0,len(events)):\n",
    "#            speaker_list.append([event_name, events[item_nb], frame_start[item_nb], frame_end[item_nb]])\n",
    "#    df = pd.DataFrame(speaker_list, columns=columns_name)\n",
    "    #df.to_csv('dialog'+str(i+1)+'_speaker_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs_speaker_event = [pd.read_csv('./data/event_timestamp/dialog'+str(i)+'_speaker_events.csv') for i in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, df in enumerate(dfs_speaker_event):\n",
    "#    dfs_speaker_event[i] = df.sort_values(by=['frame_start'])\n",
    "#    dfs_speaker_event[i] = dfs_speaker_event[i].reset_index(drop=True)\n",
    "#    dfs_speaker_event[i].to_csv('dialog'+str(i+1)+'_speaker_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_speaker_event = [pd.read_csv('./data/event_timestamp/dialog'+str(i)+'_speaker_events.csv') for i in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_speaker_event[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_speaker_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the events (speaking actor, sound direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_direction = ['r','orange','g','grey'] #left, front, right, none\n",
    "nb_speech_acts = {}\n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,1))\n",
    "    plt.title('Speech act in '+dialog_durations.keys().values[i])\n",
    "    df = dfs_speaker_event[i] \n",
    "    last_frame = int(dialog_durations.iloc[:, [i]].values[0]/40)\n",
    "    sound_df = dfs_event[i]\n",
    "    sound_dir = sound_df[sound_df['event'].str.contains('sound')][[\"frame_number\",\"event\"]].values\n",
    "    count_left = 0\n",
    "    count_front = 0\n",
    "    count_right = 0\n",
    "    count_sound_changes = 0\n",
    "    \n",
    "    #plot sound direction - come from event_timestamp_dialogx (this is the binaural audio)\n",
    "    if sound_dir[0][1] == 'no_sound_direction':\n",
    "        y = 4\n",
    "        plt.hlines(y,1,last_frame, colors=color_direction[3], linewidth=10, label='mono')\n",
    "    else:\n",
    "        for j in range(0,len(sound_dir)):\n",
    "            direction = sound_dir[j][1]\n",
    "\n",
    "            sound_start = sound_dir[j][0]\n",
    "            if j < len(sound_dir)-1:\n",
    "                next_sound_start = sound_dir[j+1][0]\n",
    "            else:\n",
    "                next_sound_start = last_frame\n",
    "                \n",
    "            if direction == 'sound_left':\n",
    "                count_sound_changes += 1\n",
    "                y = 4\n",
    "                plt.hlines(y,sound_start,next_sound_start, colors=color_direction[0], linewidth=10)\n",
    "            elif direction == 'sound_front':\n",
    "                count_sound_changes += 1\n",
    "                y = 4\n",
    "                plt.hlines(y,sound_start,next_sound_start, colors=color_direction[1], linewidth=10)\n",
    "            else:\n",
    "                count_sound_changes += 1\n",
    "                y = 4\n",
    "                plt.hlines(y,sound_start,next_sound_start, colors=color_direction[2], linewidth=10)\n",
    "    \n",
    "    #plot act of speech (come from dialogx_speaker_events, this is the real act dfs_speaker_event)\n",
    "    for j in range(0,len(df)):\n",
    "        speaker = df.loc[(df.index == j), \"speaker\"].values[0]\n",
    "        x_start = df.loc[(df.index == j), \"frame_start\"].values[0]\n",
    "        x_end = df.loc[(df.index == j), \"frame_end\"].values[0]\n",
    "        event = df.loc[(df.index == j), \"event\"].values[0]\n",
    "        if speaker == 'speaker_left':\n",
    "            count_left += 1\n",
    "            y = 3\n",
    "            plt.hlines(y,x_start,x_end, colors=color_direction[0], linewidth=10, label='left')\n",
    "            #plt.text(y, x_start+(x_end-x_start)/2, event)\n",
    "        elif speaker == 'speaker_front':\n",
    "            count_front += 1\n",
    "            y = 2\n",
    "            plt.hlines(y,x_start,x_end, colors=color_direction[1], linewidth=10, label='front')\n",
    "            #plt.text(y, x_start+(x_end-x_start)/2, event)\n",
    "        else:\n",
    "            count_right += 1\n",
    "            y = 1\n",
    "            plt.hlines(y,x_start,x_end, colors=color_direction[2], linewidth=10, label='right')\n",
    "            #plt.text(y, x_start+(x_end-x_start)/2, event)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(),loc='lower left', bbox_to_anchor=(1, 0))\n",
    "    plt.xlabel('Frames')\n",
    "    #plt.savefig(\"speech_act_dialog\"+str(i+1)+\".pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('Nb of sound changes: '+str(count_sound_changes))\n",
    "    print('Nb of speech act of actor on left: '+str(count_left))\n",
    "    print('Nb of speech act of actor on front: '+str(count_front))\n",
    "    print('Nb of speech act of actor on right: '+str(count_right))\n",
    "    print('Total nb of speech act: '+str(count_right+count_left+count_front))\n",
    "    nb_speech_acts[i] = count_right+count_left+count_front"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a similar number of act of speech (minimum = 42 in dialog 5, maximum = 54 in dialog 6). The mean number of act of speech is 46.5. So the minimum is 4.5 away from the mean and the maximum is 7.5 away of the mean. It is also worth to note that an act of speech can be a \"hmmm\" or just \"okay\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of number of transitions from one area of interest to another by the participants with the number of speech acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_aoi_transitions = {}\n",
    "for dialog_nb, dialog in enumerate(short_scanpaths.keys()):\n",
    "    ratio_aoi_transitions[dialog] = []\n",
    "    list_paths = short_scanpaths[dialog].tolist()\n",
    "    for i in list_paths:\n",
    "        ratio_aoi_transitions[dialog].append(len(i)/nb_speech_acts[dialog_nb])\n",
    "ratio_aoi_transitions = pd.DataFrame(ratio_aoi_transitions, columns=short_scanpaths.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio_aoi_transitions.to_csv('ratio_aoi_transitions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn taking event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify turn taking events, I will first identify the transition between speakers when there is no overlap between them.\n",
    "To do this I first merge the events occuring during other ones and then I check the gaps (or silences) between the events left which will be the transitions (without the starting silence and ending silence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge overlapping intervals (ref: https://www.geeksforgeeks.org/merging-intervals/):\n",
    "* 1) Sort all intervals in increasing order of start time.\n",
    "* 2) Traverse sorted intervals starting from first interval, \n",
    "   do following for every interval.\n",
    "       a) If current interval is not first interval and it \n",
    "         overlaps with previous interval, then merge it with\n",
    "         previous interval. Keep doing it while the interval\n",
    "         overlaps with the previous one.         \n",
    "       b) Else add current interval to output list of intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in O(n Log n) time and O(1) extra space \n",
    "def mergeIntervals(arr): \n",
    "          \n",
    "        # Sorting based on the increasing order  \n",
    "        # of the start intervals \n",
    "        arr.sort(key = lambda x: x[0])  \n",
    "          \n",
    "        # array to hold the merged intervals \n",
    "        m = [] \n",
    "        s = -10000\n",
    "        max = -100000\n",
    "        for i in range(len(arr)): \n",
    "            a = arr[i] \n",
    "            if a[0] > max: \n",
    "                if i != 0: \n",
    "                    m.append([s,max]) \n",
    "                max = a[1] \n",
    "                s = a[0] \n",
    "            else: \n",
    "                if a[1] >= max: \n",
    "                    max = a[1] \n",
    "          \n",
    "        #'max' value gives the last point of  \n",
    "        # that particular interval \n",
    "        # 's' gives the starting point of that interval \n",
    "        # 'm' array contains the list of all merged intervals \n",
    "  \n",
    "        if max != -100000 and [s, max] not in m: \n",
    "            m.append([s, max]) \n",
    "        #print(\"The Merged Intervals are :\", end = \" \") \n",
    "        #for i in range(len(m)): \n",
    "            #print(m[i], end = \" \") \n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_silences = {}\n",
    "dialog_transitions = {}\n",
    "for i in range(0,6):\n",
    "    df = dfs_speaker_event[i][[\"frame_start\",\"frame_end\"]]\n",
    "    last_frame = int(dialog_durations.iloc[:, [i]].values[0]/40)\n",
    "    lst = [[1,1]] + df.to_numpy().tolist() + [[last_frame,last_frame]]\n",
    "    non_overlapping_lst = mergeIntervals(lst)\n",
    "    #find transition intervals\n",
    "    lst = non_overlapping_lst\n",
    "    silences = [(lst[j][1], lst[j+1][0]) for j in range(len(lst)-1) if lst[j][1] < lst[j+1][0]]\n",
    "    dialog_silences[i] = silences\n",
    "    dialog_transitions[i] = silences[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silences[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the distribution of the durations of transitions in each dialog :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    transitions_dur = [j[1]-j[0] for j in dialog_transitions[i]]\n",
    "    plt.title('Transitions in dialog'+str(i+1))\n",
    "    plt.hist(transitions_dur)\n",
    "    plt.xlabel('Durations in nb of frame')\n",
    "    plt.ylabel('Nb of transitions')\n",
    "    plt.show()\n",
    "    \n",
    "    c = len([j for j in transitions_dur if j < 8])\n",
    "    print('Total nb of transitions: '+str(len(dialog_transitions[i])))\n",
    "    print('Total nb of transitions below 8 frames: '+str(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the turn transitions are mostly very fast in each dialog (between 40 to 320 ms). So we can separate fast turn transitions (durations of 320 ms or less) and normal turn transitions (+320ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_fast_transitions = {}\n",
    "dialog_normal_transitions = {}\n",
    "for i in range(0,6):\n",
    "    fast_transitions = [(j[0],j[1]) for j in dialog_transitions[i] if (j[1]-j[0])<=8]\n",
    "    normal_transitions = [(j[0],j[1]) for j in dialog_transitions[i] if (j[1]-j[0])>8]\n",
    "    dialog_normal_transitions[i] = normal_transitions\n",
    "    dialog_fast_transitions[i] = fast_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialog_transitions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialog_normal_transitions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialog_fast_transitions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the transitions I construct a window of 2 sec (+-25 frames from the center) for the fast transition and a window of 5 sec (+-63 frames from the center) for the normal transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_fast_window = 25\n",
    "half_normal_window = 63\n",
    "analysis_windows_fast = {}\n",
    "analysis_windows_normal = {}\n",
    "\n",
    "for i in range(0,6):\n",
    "    analysis_windows_fast[i]=[]\n",
    "    analysis_windows_normal[i]=[]\n",
    "    fast_trans = dialog_fast_transitions[i]\n",
    "    normal_trans = dialog_normal_transitions[i]\n",
    "    for trans in fast_trans:\n",
    "        start = round((trans[0]+trans[1])/2)-half_fast_window\n",
    "        end = round((trans[0]+trans[1])/2)+half_fast_window\n",
    "        analysis_windows_fast[i].append(tuple([start,end]))\n",
    "    for trans in normal_trans:\n",
    "        start = round((trans[0]+trans[1])/2)-half_normal_window\n",
    "        end = round((trans[0]+trans[1])/2)+half_normal_window\n",
    "        analysis_windows_normal[i].append(tuple([start,end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_windows_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_windows_fast[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of fixation dispersion at turn transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fast_transitions_disp = {}\n",
    "for dialog_nb in range(0,6):\n",
    "    mean_fast_transitions_disp[dialog_nb] = []\n",
    "    for window_nb, window in enumerate(analysis_windows_fast[dialog_nb]):\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title('Dispersion at turn transition (window frames: '+str(frame_start)+' to '+str(frame_end)+\n",
    "                  ') (transition frames: '+str(dialog_fast_transitions[dialog_nb][window_nb][0])+' to '+str(dialog_fast_transitions[dialog_nb][window_nb][1])+') in dialog '+str(dialog_nb+1)\n",
    "                 + '. Silence is marked in orange.'\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        x = [point[0]/40 for point in list_points_dialog_disp[dialog_nb][frame_start:frame_end]]\n",
    "        y = [point[1] for point in list_points_dialog_disp[dialog_nb][frame_start:frame_end]]\n",
    "        mean_fast_transitions_disp[dialog_nb].append(np.mean(y))\n",
    "        plt.plot(x, y, marker='x', color='cornflowerblue')\n",
    "        plt.xlabel('Frames')\n",
    "        plt.ylabel('Dispersion')\n",
    "        #plt.legend()\n",
    "        plt.axvspan(dialog_fast_transitions[dialog_nb][window_nb][0], dialog_fast_transitions[dialog_nb][window_nb][1], color='bisque', alpha=0.4) ## highlight silent area\n",
    "        \n",
    "        plt.show()\n",
    "        #plt.savefig('dispersion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_nb = 0\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    df = pd.DataFrame(mean_fast_transitions_disp[dialog_nb],columns=[item_name])\n",
    "    df.to_csv('./results/transitions/fast-new/'+item_name+'_mean_dispersion_transitions_fast_per_frame.csv', index=False)\n",
    "    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion_fast_transitions = {}\n",
    "for dialog in mean_fast_transitions_disp:\n",
    "    mean_dispersion_fast_transitions[dialog+1]=np.mean(mean_fast_transitions_disp[dialog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_dispersion_fast_transitions    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_normal_transitions_disp = {}\n",
    "for dialog_nb in range(0,6):\n",
    "    mean_normal_transitions_disp[dialog_nb] = []\n",
    "    for window_nb, window in enumerate(analysis_windows_normal[dialog_nb]):\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title('Dispersion at turn transition (window frames: '+str(frame_start)+' to '+str(frame_end)+\n",
    "                  ') (transition frames: '+str(dialog_normal_transitions[dialog_nb][window_nb][0])+' to '+str(dialog_normal_transitions[dialog_nb][window_nb][1])+') in dialog '+str(dialog_nb+1)\n",
    "                  + '. Silence is marked in orange.'   \n",
    "                 )\n",
    "        x = [point[0]/40 for point in list_points_dialog_disp[dialog_nb][frame_start:frame_end]]\n",
    "        y = [point[1] for point in list_points_dialog_disp[dialog_nb][frame_start:frame_end]]\n",
    "        \n",
    "        mean_normal_transitions_disp[dialog_nb].append(np.mean(y))\n",
    "        plt.plot(x, y, marker='x', color='cornflowerblue')\n",
    "        plt.xlabel('Frames')\n",
    "        plt.ylabel('Dispersion')\n",
    "        \n",
    "        plt.axvspan(dialog_normal_transitions[dialog_nb][window_nb][0], dialog_normal_transitions[dialog_nb][window_nb][1], color='bisque', alpha=0.4) ## highlight silent area\n",
    "        #plt.legend()\n",
    "        plt.show()\n",
    "        #plt.savefig('dispersion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_nb = 0\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    df = pd.DataFrame(mean_normal_transitions_disp[dialog_nb],columns=[item_name])\n",
    "    df.to_csv('./results/transitions/normal-new/' +item_name+'_mean_dispersion_transitions_normal_per_frame.csv', index=False)\n",
    "    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion_normal_transitions = {}\n",
    "for dialog in mean_normal_transitions_disp:\n",
    "    mean_dispersion_normal_transitions[dialog+1]=np.mean(mean_normal_transitions_disp[dialog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion_normal_transitions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion_normal_transitions   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of aoi fixation ratios at turn transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(aoi_ratios_per_frame.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "areas_of_interest = ['L','R','F','e']\n",
    "aoi_ratio_fast_transitions = {}\n",
    "for dialog_nb in range(0,6):\n",
    "    aoi_ratio_fast_transitions[dialog_nb] = {}\n",
    "    for window_nb, window in enumerate(analysis_windows_fast[dialog_nb]):\n",
    "        aoi_ratio_fast_transitions[dialog_nb][window_nb] = {}\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "        plt.figure(figsize=(20,4))\n",
    "        plt.title('Fixation ratios on AoIs over frames for dialog '+str(dialog_nb+1)+' (window frames: '+str(frame_start)+' to '+str(frame_end)+') (transition frames: '+str(dialog_fast_transitions[dialog_nb][window_nb][0])+' to '+str(dialog_fast_transitions[dialog_nb][window_nb][1])+')'\n",
    "                 + '. Silence is marked in orange.' \n",
    "                 )\n",
    "        for i in areas_of_interest:\n",
    "            aoi_ratio_fast_transitions[dialog_nb][window_nb][i] = []\n",
    "            x = []\n",
    "            y = []\n",
    "            for frame in range(frame_start-1, frame_end):\n",
    "                x.append(frame)\n",
    "                y.append(aoi_ratios_per_frame[list(aoi_ratios_per_frame.keys())[dialog_nb]][frame][i])\n",
    "                aoi_ratio_fast_transitions[dialog_nb][window_nb][i].append(y)\n",
    "            if i == 'L':\n",
    "                plt.plot(x, y, label='left', marker='o', color='r')\n",
    "            elif i == 'R':\n",
    "                plt.plot(x, y, label='right', marker='x', color='g')\n",
    "            elif i == 'F':\n",
    "                plt.plot(x, y, label='front', marker='^', color='orange')\n",
    "            else:\n",
    "                plt.plot(x, y, label='exterior', marker='+', color='gray')\n",
    "                \n",
    "        plt.axvspan(dialog_fast_transitions[dialog_nb][window_nb][0], dialog_fast_transitions[dialog_nb][window_nb][1], color='bisque', alpha=0.4) ## highlight silent area       \n",
    "        \n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Fixation ratio')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        #plt.savefig('dispersion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_of_interest = ['L','R','F','e']\n",
    "aoi_ratio_normal_transitions = {}\n",
    "for dialog_nb in range(0,6):\n",
    "    aoi_ratio_normal_transitions[dialog_nb] = {}\n",
    "    for window_nb, window in enumerate(analysis_windows_normal[dialog_nb]):\n",
    "        try:\n",
    "            aoi_ratio_normal_transitions[dialog_nb][window_nb] = {}\n",
    "            frame_start = window[0]\n",
    "            frame_end = window[1]\n",
    "            if frame_start < 0:\n",
    "                frame_start = 0\n",
    "            if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "                frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "            plt.figure(figsize=(20,4))\n",
    "            plt.title('Fixation ratios on AoIs over frames for dialog '+str(dialog_nb+1)+' (window frames: '+str(frame_start)+' to '+str(frame_end)+') (transition frames: '+str(dialog_normal_transitions[dialog_nb][window_nb][0])+' to '+str(dialog_normal_transitions[dialog_nb][window_nb][1])+')'\n",
    "                     + '. Silence is marked in orange.' \n",
    "                     )\n",
    "            for i in areas_of_interest:\n",
    "                aoi_ratio_normal_transitions[dialog_nb][window_nb][i] = []\n",
    "                x = []\n",
    "                y = []\n",
    "                for frame in range(frame_start-1, frame_end):\n",
    "                    x.append(frame)\n",
    "                    y.append(aoi_ratios_per_frame[list(aoi_ratios_per_frame.keys())[dialog_nb]][frame][i])\n",
    "                    aoi_ratio_normal_transitions[dialog_nb][window_nb][i].append(y)\n",
    "                if i == 'L':\n",
    "                    plt.plot(x, y, label='left', marker='o', color='r')\n",
    "                elif i == 'R':\n",
    "                    plt.plot(x, y, label='right', marker='x', color='g')\n",
    "                elif i == 'F':\n",
    "                    plt.plot(x, y, label='front', marker='^', color='orange')\n",
    "                else:\n",
    "                    plt.plot(x, y, label='exterior', marker='+', color='gray')\n",
    "\n",
    "            plt.axvspan(dialog_normal_transitions[dialog_nb][window_nb][0], dialog_normal_transitions[dialog_nb][window_nb][1], color='bisque', alpha=0.4) ## highlight silent area       \n",
    "\n",
    "            plt.xlabel('Frame')\n",
    "            plt.ylabel('Fixation ratio')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        except:\n",
    "            print('Fixation ratios on AoIs over frames for dialog '+str(dialog_nb+1)+' (window frames: '+str(frame_start)+' to '+str(frame_end)+') (transition frames: '+str(dialog_normal_transitions[dialog_nb][window_nb][0])+' to '+str(dialog_normal_transitions[dialog_nb][window_nb][1])+')'\n",
    "                     + ' cannot be shown.')\n",
    "        #plt.savefig('dispersion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_aoi_ratio_fast_transitions = {}\n",
    "for dialog in aoi_ratio_fast_transitions:\n",
    "    mean_aoi_ratio_fast_transitions[dialog] = {}\n",
    "    for window in aoi_ratio_fast_transitions[dialog]:\n",
    "        mean_aoi_ratio_fast_transitions[dialog][window] = {}\n",
    "        for aoi in aoi_ratio_fast_transitions[dialog][window]:\n",
    "            mean_aoi_ratio_fast_transitions[dialog][window][aoi] = np.mean(aoi_ratio_fast_transitions[dialog][window][aoi])\n",
    "            \n",
    "mean_aoi_ratio_fast_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of distance to center at turn transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_points_dialog_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_nb in range(0,6):\n",
    "    for window_nb, window in enumerate(analysis_windows_fast[dialog_nb]):\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_center[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_center[dialog_nb])-1\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title('Distance to center at turn transition (window: '+str(frame_start)+' to '+str(frame_end)+\n",
    "                  ') (transition: '+str(dialog_fast_transitions[dialog_nb][window_nb][0])+' to '+str(dialog_fast_transitions[dialog_nb][window_nb][1])+') in dialog '+str(dialog_nb+1))\n",
    "        x = [point[0]/40 for point in list_points_dialog_center[dialog_nb][frame_start:frame_end]]\n",
    "        y = [point[1] for point in list_points_dialog_center[dialog_nb][frame_start:frame_end]]\n",
    "        plt.plot(x, y, marker='x', color='r')\n",
    "        plt.xlabel('Frames')\n",
    "        plt.ylabel('Distance to center')\n",
    "        #plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of scanpaths similarity at turn transitions (also patterns? transition probability?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: visually look at speech act v.s. genetic scanpath at turning points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2: 3D plot of fixation of each participant during transition period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are more than one fixation in a frame\n",
    "for dialog_nb, dialog in enumerate(fixation_points_per_participant_per_frame):\n",
    "    print(dialog_nb)\n",
    "    for i in range (0,len(dialog)):\n",
    "            for frame_nb in range(0, len(dialog[i])):  \n",
    "                if len(dialog[i][frame_nb]) > 1:\n",
    "                    print(\"dialog: \" + str(dialog_nb))\n",
    "                    print(\"participant: \" + str(i))\n",
    "                    print(\"frame: \" + str(frame_nb))\n",
    "                    print(dialog[i][frame_nb])\n",
    "                    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example two fixations in one frame\n",
    "dialog[41][2918]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eample one fixation in one frame\n",
    "dialog[41][2919]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just take the first fixation if there are more than one fixations in a frame as the value does not change significantly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_nb, dialog in enumerate(fixation_points_per_participant_per_frame):\n",
    "    \n",
    "    # fast transition\n",
    "    for window_nb, window in enumerate(analysis_windows_fast[dialog_nb]):\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize = (12, 8))\n",
    "        ax = plt.axes(projection =\"3d\")\n",
    "        plt.title(\"3D representation of scanpath of each participant in dialog \"+str(dialog_nb+1) + \n",
    "                  \" during fast transitions\" + \" (window frames: \" +str(frame_start) + \" to \" +str(frame_end)+ \")\" ) \n",
    "        \n",
    "        # plot image\n",
    "        img = read_png('./screenshot/dialog' + str(dialog_nb+1) + '_screenshot.png')\n",
    "        x, y = ogrid[0:img.shape[0], 0:img.shape[1]]\n",
    "        # ax = gca(projection='3d')\n",
    "        ax.plot_surface(x, y, np.atleast_2d(frame_start), rstride=8, cstride=8, facecolors=img, alpha=0.2)\n",
    "\n",
    "        for i in range (0,42): # loop through 42 participantw\n",
    "            participant = dialog[i]\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "            \n",
    "            for frame_nb in range(frame_start-1, frame_end):\n",
    "                if participant[frame_nb] != []:\n",
    "                    x.append(participant[frame_nb][0][1])\n",
    "                    y.append(participant[frame_nb][0][0])\n",
    "                    z.append(frame_nb)\n",
    "\n",
    "            ax.set_xlim(0,720)\n",
    "            ax.set_ylim(0,1280)\n",
    "            ax.set_zlim(frame_start,frame_end)\n",
    "\n",
    "            ax.set_xlabel(\"y\")\n",
    "            ax.set_ylabel(\"x\")\n",
    "            ax.set_zlabel(\"frames\")\n",
    "            ax.plot3D(np.array(x), np.array(y), np.array(z))\n",
    "        ax.view_init(elev=25, azim=-15)\n",
    "        plt.savefig('./scanpath_plot/fast_transition/dialog'+ str(dialog_nb+1)+'/' + 'window_start_'+str(frame_start)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_nb, dialog in enumerate(fixation_points_per_participant_per_frame):\n",
    "    \n",
    "    # fast transition\n",
    "    for window_nb, window in enumerate(analysis_windows_normal[dialog_nb]):\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize = (12, 8))\n",
    "        ax = plt.axes(projection =\"3d\")\n",
    "        plt.title(\"3D representation of scanpath of each participant in dialog \"+str(dialog_nb+1) + \n",
    "                  \" during normal transitions\" + \" (window frames: \" +str(frame_start) + \" to \" +str(frame_end)+ \")\" ) \n",
    "        \n",
    "        # plot image\n",
    "        img = read_png('./screenshot/dialog' + str(dialog_nb+1) + '_screenshot.png')\n",
    "        x, y = ogrid[0:img.shape[0], 0:img.shape[1]]\n",
    "        # ax = gca(projection='3d')\n",
    "        ax.plot_surface(x, y, np.atleast_2d(frame_start), rstride=8, cstride=8, facecolors=img, alpha=0.2)\n",
    "\n",
    "        for i in range (0,42): # loop through 42 participantw\n",
    "            participant = dialog[i]\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "            \n",
    "            for frame_nb in range(frame_start-1, frame_end):\n",
    "                if participant[frame_nb] != []:\n",
    "                    x.append(participant[frame_nb][0][1])\n",
    "                    y.append(participant[frame_nb][0][0])\n",
    "                    z.append(frame_nb)\n",
    "\n",
    "            ax.set_xlim(0,720)\n",
    "            ax.set_ylim(0,1280)\n",
    "            ax.set_zlim(frame_start,frame_end)\n",
    "\n",
    "            ax.set_xlabel(\"y\")\n",
    "            ax.set_ylabel(\"x\")\n",
    "            ax.set_zlabel(\"frames\")\n",
    "            ax.plot3D(np.array(x), np.array(y), np.array(z))\n",
    "        ax.view_init(elev=25, azim=-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple speaker event (sense of interruption/agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_fast_window = 25\n",
    "half_normal_window = 63\n",
    "analysis_windows_fast = {}\n",
    "analysis_windows_normal = {}\n",
    "\n",
    "for i in range(0,6):\n",
    "    analysis_windows_fast[i]=[]\n",
    "    analysis_windows_normal[i]=[]\n",
    "    fast_trans = dialog_fast_transitions[i]\n",
    "    normal_trans = dialog_normal_transitions[i]\n",
    "    for trans in fast_trans:\n",
    "        start = round((trans[0]+trans[1])/2)-half_fast_window\n",
    "        end = round((trans[0]+trans[1])/2)+half_fast_window\n",
    "        analysis_windows_fast[i].append(tuple([start,end]))\n",
    "    for trans in normal_trans:\n",
    "        start = round((trans[0]+trans[1])/2)-half_normal_window\n",
    "        end = round((trans[0]+trans[1])/2)+half_normal_window\n",
    "        analysis_windows_normal[i].append(tuple([start,end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple([start,end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interruptions = {}\n",
    "\n",
    "# half_fast_window = 25\n",
    "# half_normal_window = 63\n",
    "# analysis_windows_fast = {}\n",
    "# analysis_windows_normal = {}\n",
    "\n",
    "# for i in range(0,6):\n",
    "#     analysis_windows_fast[i]=[]\n",
    "#     analysis_windows_normal[i]=[]\n",
    "#     fast_trans = dialog_fast_transitions[i]\n",
    "#     normal_trans = dialog_normal_transitions[i]\n",
    "#     for trans in fast_trans:\n",
    "#         start = round((trans[0]+trans[1])/2)-half_fast_window\n",
    "#         end = round((trans[0]+trans[1])/2)+half_fast_window\n",
    "#         analysis_windows_fast[i].append(tuple([start,end]))\n",
    "#     for trans in normal_trans:\n",
    "#         start = round((trans[0]+trans[1])/2)-half_normal_window\n",
    "#         end = round((trans[0]+trans[1])/2)+half_normal_window\n",
    "#         analysis_windows_normal[i].append(tuple([start,end]))\n",
    "\n",
    "    \n",
    "    \n",
    "for dialog_nb in range(0,6):\n",
    "    interruptions[dialog_nb]=[]\n",
    "    df = dfs_speaker_event[dialog_nb][[\"frame_start\",\"frame_end\"]]\n",
    "    df = df.sort_values(by=['frame_start'])\n",
    "    \n",
    "    for i in range(0, df.shape[0]): # iterate rows\n",
    "        df_prev = df.iloc[:i]\n",
    "        for j in range(0, df_prev.shape[0]):\n",
    "            if df.iloc[i]['frame_end'] < df_prev.iloc[j]['frame_end']:\n",
    "                interr = tuple([df.iloc[i]['frame_start'],df.iloc[i]['frame_end']]) \n",
    "                interruptions[dialog_nb].append(interr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(interruptions)):\n",
    "    print(len(interruptions[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of fixation dispersion at interruptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a window of +-2 sec (25 frames) for the interruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_fast_window = 25\n",
    "analysis_interruptions = {}\n",
    "\n",
    "for i in range(0,6):\n",
    "    analysis_interruptions[i]=[]\n",
    "\n",
    "    interr = interruptions[i]\n",
    "    normal_trans = dialog_normal_transitions[i]\n",
    "    for trans in interr:\n",
    "        start = round((trans[0]+trans[1])/2)-half_fast_window\n",
    "        end = round((trans[0]+trans[1])/2)+half_fast_window\n",
    "        analysis_interruptions[i].append(tuple([int(start),int(end)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_interruption_disp = {}\n",
    "for dialog_nb in range(0,6):\n",
    "    mean_interruption_disp[dialog_nb] = []\n",
    "    for window_nb, window in enumerate(analysis_interruptions[dialog_nb]):\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title('Dispersion at interruption (window frames: '+str(frame_start)+' to '+str(frame_end)+\n",
    "                  ') (transition frames: '+str(interruptions[dialog_nb][window_nb][0])+' to '+str(interruptions[dialog_nb][window_nb][1])+') in dialog '+str(dialog_nb+1)\n",
    "                 + '. Interruption is marked in pink.'\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        x = [point[0]/40 for point in list_points_dialog_disp[dialog_nb][frame_start:frame_end]]\n",
    "        y = [point[1] for point in list_points_dialog_disp[dialog_nb][frame_start:frame_end]]\n",
    "        mean_interruption_disp[dialog_nb].append(np.mean(y))\n",
    "        plt.plot(x, y, marker='x', color='cornflowerblue')\n",
    "        plt.xlabel('Frames')\n",
    "        plt.ylabel('Dispersion')\n",
    "        #plt.legend()\n",
    "        plt.axvspan(interruptions[dialog_nb][window_nb][0], interruptions[dialog_nb][window_nb][1], color='pink', alpha=0.3) ## highlight silent area\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_nb = 0\n",
    "for item_name in fixations_original_all.index.unique():\n",
    "    df = pd.DataFrame(mean_interruption_disp[dialog_nb],columns=[item_name])\n",
    "    df.to_csv('./results/interruptions/dispersion/' +item_name+'_mean_dispersion_interruption_per_frame.csv', index=False)\n",
    "    dialog_nb = dialog_nb+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion_interruption = {}\n",
    "for dialog in mean_interruption_disp:\n",
    "    mean_dispersion_interruption[dialog+1]=np.mean(mean_interruption_disp[dialog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dispersion_interruption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of AOI fixation ratio at turn interruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_of_interest = ['L','R','F','e']\n",
    "aoi_ratio_interruptions = {}\n",
    "for dialog_nb in range(0,6):\n",
    "    aoi_ratio_interruptions[dialog_nb] = {}\n",
    "    for window_nb, window in enumerate(analysis_interruptions[dialog_nb]):\n",
    "        aoi_ratio_interruptions[dialog_nb][window_nb] = {}\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "        plt.figure(figsize=(20,4))\n",
    "        plt.title('Fixation ratios on AoIs over frames for dialog '+str(dialog_nb+1)+' (window frames: '+str(frame_start)+' to '+str(frame_end)+') (transition frames: '+str(interruptions[dialog_nb][window_nb][0])+' to '+str(interruptions[dialog_nb][window_nb][1])+')'\n",
    "                 + '. Silence is marked in pink.' \n",
    "                 )\n",
    "        for i in areas_of_interest:\n",
    "            aoi_ratio_interruptions[dialog_nb][window_nb][i] = []\n",
    "            x = []\n",
    "            y = []\n",
    "            for frame in range(frame_start-1, frame_end):\n",
    "                x.append(frame)\n",
    "                y.append(aoi_ratios_per_frame[list(aoi_ratios_per_frame.keys())[dialog_nb]][frame][i])\n",
    "                aoi_ratio_interruptions[dialog_nb][window_nb][i].append(y)\n",
    "            if i == 'L':\n",
    "                plt.plot(x, y, label='left', marker='o', color='r')\n",
    "            elif i == 'R':\n",
    "                plt.plot(x, y, label='right', marker='x', color='g')\n",
    "            elif i == 'F':\n",
    "                plt.plot(x, y, label='front', marker='^', color='orange')\n",
    "            else:\n",
    "                plt.plot(x, y, label='exterior', marker='+', color='gray')\n",
    "                \n",
    "        plt.axvspan(interruptions[dialog_nb][window_nb][0], interruptions[dialog_nb][window_nb][1], color='pink', alpha=0.3) ## highlight silent area       \n",
    "        \n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Fixation ratio')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        #plt.savefig('dispersion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of scanpaths similarity at interruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_nb, dialog in enumerate(fixation_points_per_participant_per_frame):\n",
    "    \n",
    "    # fast transition\n",
    "    for window_nb, window in enumerate(analysis_interruptions[dialog_nb]):\n",
    "        frame_start = window[0]\n",
    "        frame_end = window[1]\n",
    "        if frame_start < 0:\n",
    "            frame_start = 0\n",
    "        if frame_end > len(list_points_dialog_disp[dialog_nb])-1:\n",
    "            frame_end = len(list_points_dialog_disp[dialog_nb])-1\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize = (12, 8))\n",
    "        ax = plt.axes(projection =\"3d\")\n",
    "        plt.title(\"3D representation of scanpath of each participant in dialog \"+str(dialog_nb+1) + \" during interruptions\" + \" (window frames: \" +str(frame_start) + \" to \" +str(frame_end)+ \")\" ) \n",
    "        \n",
    "        # plot image\n",
    "        # fn = get_sample_data(\"dialog5_screenshot.png\", asfileobj=False)\n",
    "        img = read_png('./screenshot/dialog' + str(dialog_nb+1) + '_screenshot.png')\n",
    "        x, y = ogrid[0:img.shape[0], 0:img.shape[1]]\n",
    "        # ax = gca(projection='3d')\n",
    "        ax.plot_surface(x, y, np.atleast_2d(frame_start), rstride=8, cstride=8, facecolors=img, alpha=0.2)\n",
    "\n",
    "        for i in range (0,42): # loop through 42 participantw\n",
    "            participant = dialog[i]\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "            \n",
    "            for frame_nb in range(frame_start-1, frame_end):\n",
    "                if participant[frame_nb] != []:\n",
    "                    x.append(participant[frame_nb][0][1])\n",
    "                    y.append(participant[frame_nb][0][0])\n",
    "                    z.append(frame_nb)\n",
    "\n",
    "            ax.set_xlim(0,720)\n",
    "            ax.set_ylim(0,1280)\n",
    "            ax.set_zlim(frame_start,frame_end)\n",
    "\n",
    "            ax.set_xlabel(\"y\")\n",
    "            ax.set_ylabel(\"x\")\n",
    "            ax.set_zlabel(\"frames\")\n",
    "            ax.plot3D(np.array(x), np.array(y), np.array(z))\n",
    "        ax.view_init(elev=25, azim=-15)\n",
    "        plt.savefig('./scanpath_plot/interruptions/dialog'+ str(dialog_nb+1)+'/' + 'window_start_'+str(frame_start)+'.png')\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
